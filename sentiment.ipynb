{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pandas import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburbs = []\n",
    "subs = open('areas.txt', 'r')\n",
    "for line in subs:\n",
    "    line = line.replace('(', '')\n",
    "    line = line.replace(')', '')\n",
    "    line = line.strip()\n",
    "    suburbs.append(line)\n",
    "subs.close\n",
    "print(suburbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for i in range(0, len(suburbs)):\n",
    "  filenames.append(\"./Reviews/\"+str(suburbs[i])+\"/reviews.csv\")\n",
    "  # filenames = [\n",
    "  #             \"./Reviews/ANUJA HOSPITAL/reviews.csv\",\n",
    "  #           ]\n",
    "\n",
    "# merging two csv files\n",
    "df = pd.concat(\n",
    "    map(pd.read_csv, filenames), ignore_index=True)\n",
    "\n",
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_remove_translated = []\n",
    "\n",
    "reviews_dict = df.to_dict('list')\n",
    "\n",
    "for review in reviews_dict['Review']:\n",
    "  review_sep = str(review).split(\"(Translated by Google) \")\n",
    "  \n",
    "  # Jika terdapat (Translated by Google)\n",
    "  if review_sep[0] == \"\":\n",
    "    review_sep = (\"\".join(review_sep)).split(\"(Original)\")\n",
    "    review_sep = review_sep[0]\n",
    "    review = \"\".join(review_sep)\n",
    "  \n",
    "  review_remove_translated.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_dict['Review'] = review_remove_translated\n",
    "df = pd.DataFrame(reviews_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review):\n",
    "    return re.sub('[^a-zA-Z]', ' ', review).lower()\n",
    "  \n",
    "df['cleaned_review'] = df['Review'].apply(lambda x: clean_review(str(x)))\n",
    "df['label'] = df['Rating'].map({\"1 star\":0, \"2 stars\":0, \"3 stars\":0, \"4 stars\":1, \"5 stars\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punct(review):\n",
    "    count = sum([1 for char in review if char in string.punctuation])\n",
    "    return round(count/(len(review) - review.count(\" \")), 3)*100\n",
    "  \n",
    "df['review_len'] = df['Review'].apply(lambda x: len(str(x)) - str(x).count(\" \"))\n",
    "df['punct'] = df['Review'].apply(lambda x: count_punct(str(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_review(review):\n",
    "    tokenized_review = review.split()\n",
    "    return tokenized_review\n",
    "  \n",
    "df['tokens'] = df['cleaned_review'].apply(lambda x: tokenize_review(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "all_stopwords = stopwords.words('english')\n",
    "all_stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_review(token_list):\n",
    "    return \" \".join([lemmatizer.lemmatize(token) for token in token_list if not token in set(all_stopwords)])\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "df['lemmatized_review'] = df['tokens'].apply(lambda x: lemmatize_review(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Shape of the dataset, and breakdown of the classes\n",
    "print(f\"Input data has { len(df) } rows and { len(df.columns) } columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of null in label: { df['Rating'].isnull().sum() }\")\n",
    "print(f\"Number of null in text: { df['Review'].isnull().sum() }\")\n",
    "sns.countplot(x='Rating', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['lemmatized_review', 'review_len', 'punct']]\n",
    "y = df['label']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_df = 0.5, min_df = 2) # ignore terms that occur in more than 50% documents and the ones that occur in less than 2\n",
    "tfidf_train = tfidf.fit_transform(X_train['lemmatized_review'])\n",
    "tfidf_test = tfidf.transform(X_test['lemmatized_review'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['review_len', 'punct']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "X_test_vect = pd.concat([X_test[['review_len', 'punct']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vect, y_train)\n",
    "naive_bayes_pred = classifier.predict(X_test_vect)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, naive_bayes_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "class_label = [\"negative\", \"positive\"]\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, naive_bayes_pred), index=class_label, columns=class_label)\n",
    "sns.heatmap(df_cm, annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=150)\n",
    "classifier.fit(X_train_vect, y_train)\n",
    "random_forest_pred = classifier.predict(X_test_vect)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, random_forest_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "class_label = [\"negative\", \"positive\"]\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, random_forest_pred), index=class_label, columns=class_label)\n",
    "sns.heatmap(df_cm, annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_vect, y_train)\n",
    "log_reg_pred = classifier.predict(X_test_vect)\n",
    "# Classification report\n",
    "print(classification_report(y_test, log_reg_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "class_label = [\"negative\", \"positive\"]\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, log_reg_pred), index=class_label, columns=class_label)\n",
    "sns.heatmap(df_cm, annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train_vect, y_train)\n",
    "svm_pred = classifier.predict(X_test_vect)\n",
    "# Classification report\n",
    "print(classification_report(y_test, svm_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "class_label = [\"negative\", \"positive\"]\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, svm_pred), index=class_label, columns=class_label)\n",
    "sns.heatmap(df_cm, annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier.fit(X_train_vect, y_train)\n",
    "knn_pred = classifier.predict(X_test_vect)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, knn_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "class_label = [\"negative\", \"positive\"]\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, knn_pred), index=class_label, columns=class_label)\n",
    "sns.heatmap(df_cm, annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "classifier = ExtraTreesClassifier(n_estimators=150, random_state=50)\n",
    "classifier.fit(X_train_vect, y_train)\n",
    "extra_trees_pred = classifier.predict(X_test_vect)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, extra_trees_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "class_label = [\"negative\", \"positive\"]\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, extra_trees_pred), index=class_label, columns=class_label)\n",
    "sns.heatmap(df_cm, annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = [\n",
    "          MultinomialNB(),\n",
    "          LogisticRegression(),\n",
    "          RandomForestClassifier(n_estimators = 150),\n",
    "          SVC(kernel = 'linear'),\n",
    "          KNeighborsClassifier(n_neighbors = 5),\n",
    "          ExtraTreesClassifier(n_estimators=150, random_state=50)\n",
    "         ]\n",
    "names = [\"Naive Bayes\", \"Logistic Regression\", \"Random Forest\", \"SVM\", \"KNN\", \"Extra Trees\"]\n",
    "for model, name in zip(models, names):\n",
    "    print(name)\n",
    "    for score in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "        print(f\" {score} - {cross_val_score(model, X_train_vect, y_train, scoring=score, cv=10).mean()} \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 10)\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# classifier = ExtraTreesClassifier(n_estimators=150, random_state=50)\n",
    "\n",
    "classifier.fit(tfidf_train, y_train)\n",
    "classifier.score(tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"Bad\", \"Good\", \"I love the service, it's really good\", \"Worst\"]\n",
    "vect = tfidf.transform(data).toarray()\n",
    "\n",
    "my_pred = classifier.predict(vect)\n",
    "print(my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_cv = cv.fit_transform(df['lemmatized_review']) # Fit the Data\n",
    "y_cv = df['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_cv, y_cv, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(X_train_cv, y_train_cv)\n",
    "clf.score(X_test_cv, y_test_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"Bad\", \"Worst service, don't go there\", \"Services are OK\", \"Good service\", \"The nurse is so kind\"]\n",
    "vect = cv.transform(data).toarray()\n",
    "\n",
    "my_prediction = clf.predict(vect)\n",
    "print(my_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = float(input(\"Enter your latitude: \"))\n",
    "lon = float(input(\"Enter your longitude: \"))\n",
    "\n",
    "ran = float(input(\"Enter the range(in km): \")) #in km\n",
    "\n",
    "change_per_deg_lat = 111.2\n",
    "change_per_deg_long = 105.75\n",
    "\n",
    "df = pd.read_csv(\"modified.csv\")\n",
    "\n",
    "for row in df.itertuples():\n",
    "\n",
    "        x = abs(float(row[6]) - lon) * change_per_deg_long\n",
    "        y = abs(float(row[5]) - lat) * change_per_deg_lat\n",
    "        dist = (x**2 + y**2)**(1/2)\n",
    "\n",
    "        if dist <= ran:\n",
    "                print(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 1 0]\n",
      "29\n",
      "41\n",
      "Good\n"
     ]
    }
   ],
   "source": [
    "data = [\"Bad\", \"Worst service, don't go there\", \"Services are OK\", \"Good service\", \"The nurse is so kind\"]\n",
    "process = read_csv(\"./Reviews/Sancheti Hospital/reviews.csv\")\n",
    "data = process['Review'].to_list()\n",
    "vect = cv.transform(data).toarray()\n",
    "\n",
    "my_prediction = clf.predict(vect)\n",
    "flag = \"Bad\"\n",
    "zeroes = len(my_prediction) - np.count_nonzero(my_prediction)\n",
    "if np.count_nonzero(my_prediction) > zeroes:\n",
    "    flag = \"Good\"\n",
    "print(my_prediction)\n",
    "print(zeroes)\n",
    "print(np.count_nonzero(my_prediction))\n",
    "print(flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
